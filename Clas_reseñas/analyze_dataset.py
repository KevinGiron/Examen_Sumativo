#!/usr/bin/env python
"""
Script de an√°lisis detallado del dataset y resultados del modelo.

Genera estad√≠sticas del dataset y an√°lisis de performance.
"""

import pandas as pd
import os
from collections import Counter
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from src.data_loader import load_csv_data
from src.embeddings import Embedder

def analyze_dataset(csv_path="data/raw/reviews.csv"):
    """Analiza estad√≠sticas del dataset."""
    
    if not os.path.exists(csv_path):
        print(f"‚ùå Dataset no encontrado: {csv_path}")
        return
    
    # Cargar datos
    texts, labels = load_csv_data(csv_path)
    
    print("\n" + "="*70)
    print("AN√ÅLISIS DEL DATASET")
    print("="*70)
    
    # Estad√≠sticas generales
    print(f"\nüìä Estad√≠sticas Generales:")
    print(f"  Total de rese√±as: {len(texts)}")
    print(f"  N√∫mero de clases: {len(set(labels))}")
    print(f"  Clases: {', '.join(sorted(set(labels)))}")
    
    # Distribuci√≥n de clases
    print(f"\nüìà Distribuci√≥n de Clases:")
    class_counts = Counter(labels)
    for class_name, count in sorted(class_counts.items()):
        percentage = (count / len(labels)) * 100
        bar = "‚ñà" * int(percentage / 5)
        print(f"  {class_name:12} : {count:3} ({percentage:5.1f}%) {bar}")
    
    # Estad√≠sticas de longitud
    text_lengths = [len(text.split()) for text in texts]
    
    print(f"\nüìù Estad√≠sticas de Longitud (palabras):")
    print(f"  M√≠nimo:    {min(text_lengths)} palabras")
    print(f"  M√°ximo:    {max(text_lengths)} palabras")
    print(f"  Promedio:  {sum(text_lengths)/len(text_lengths):.1f} palabras")
    print(f"  Mediana:   {sorted(text_lengths)[len(text_lengths)//2]} palabras")
    
    # Longitud por clase
    print(f"\nüìù Longitud Promedio por Clase:")
    for class_name in sorted(set(labels)):
        class_texts = [text for text, label in zip(texts, labels) if label == class_name]
        class_lengths = [len(text.split()) for text in class_texts]
        avg_length = sum(class_lengths) / len(class_lengths)
        print(f"  {class_name:12} : {avg_length:6.1f} palabras")
    
    # Balance del dataset
    print(f"\n‚öñÔ∏è  Balance del Dataset:")
    max_count = max(class_counts.values())
    min_count = min(class_counts.values())
    imbalance_ratio = max_count / min_count
    
    print(f"  Ratio desbalance: {imbalance_ratio:.2f}x")
    if imbalance_ratio > 2:
        print(f"  ‚ö†Ô∏è  Dataset desbalanceado. Considere t√©cnicas de balanceo.")
    elif imbalance_ratio > 1.5:
        print(f"  ‚ö†Ô∏è  Ligero desbalance detectado.")
    else:
        print(f"  ‚úì Dataset bien balanceado.")
    
    # Ejemplos
    print(f"\nüìã Ejemplos de Rese√±as por Clase:")
    for class_name in sorted(set(labels)):
        example = next(text for text, label in zip(texts, labels) if label == class_name)
        preview = (example[:60] + "...") if len(example) > 60 else example
        print(f"  {class_name:12} : \"{preview}\"")
    
    print("="*70 + "\n")


def analyze_model_performance(results_dict):
    """Analiza performance del modelo."""
    
    print("\n" + "="*70)
    print("AN√ÅLISIS DE PERFORMANCE DEL MODELO")
    print("="*70)
    
    print(f"\n‚úì Modelo: {results_dict['model_type'].upper()}")
    print(f"\nüìä M√©tricas Principales:")
    print(f"  Accuracy:  {results_dict['accuracy']:.4f} ({results_dict['accuracy']*100:.2f}%)")
    print(f"  Precision: {results_dict['precision']:.4f}")
    print(f"  Recall:    {results_dict['recall']:.4f}")
    print(f"  F1-Score:  {results_dict['f1']:.4f}")
    
    print(f"\nüìà Validaci√≥n Cruzada (5-fold):")
    print(f"  F1-Score Medio: {results_dict['cv_mean']:.4f}")
    print(f"  Desv. Est√°ndar: {results_dict['cv_std']:.4f}")
    print(f"  Scores por fold: {', '.join([f'{s:.4f}' for s in results_dict['cv_scores']])}")
    
    if results_dict['cv_std'] < 0.05:
        print(f"  ‚úì Modelo estable (std < 0.05)")
    else:
        print(f"  ‚ö†Ô∏è  Alto variance entre folds (std >= 0.05)")
    
    # Matriz de confusi√≥n
    cm = results_dict['confusion_matrix']
    print(f"\nüéØ Matriz de Confusi√≥n:")
    print(f"  {cm}")
    
    print("="*70 + "\n")


def compare_embedding_quality():
    """Analiza calidad de los embeddings."""
    
    print("\n" + "="*70)
    print("AN√ÅLISIS DE EMBEDDINGS")
    print("="*70)
    
    texts, labels = load_csv_data("data/raw/reviews.csv")
    
    embedder = Embedder()
    embeddings = embedder.encode(texts[:5])  # Probar con primeros 5
    
    print(f"\nüî¢ Caracter√≠sticas de Embeddings:")
    print(f"  Modelo: SentenceTransformer (all-MiniLM-L6-v2)")
    print(f"  Dimensionalidad: {embeddings.shape[1]}")
    print(f"  Rango de valores: [{embeddings.min():.4f}, {embeddings.max():.4f}]")
    print(f"  Media: {embeddings.mean():.4f}")
    print(f"  Desviaci√≥n est√°ndar: {embeddings.std():.4f}")
    
    # Similaridad entre ejemplos de la misma clase
    print(f"\nüìç Validar separabilidad por clase:")
    print(f"  ‚úì Con buenos embeddings, textos similares tendr√°n embeddings similares")
    print(f"  ‚úì Textos de clases diferentes tendr√°n embeddings diferentes")
    
    print("="*70 + "\n")


if __name__ == "__main__":
    # Ejecutar an√°lisis
    analyze_dataset()
    
    # An√°lisis de embeddings
    if os.path.exists("data/raw/reviews.csv"):
        compare_embedding_quality()
    
    print("""
üí° INTERPRETACI√ìN DE RESULTADOS:

‚úì DATASET SALUDABLE (< 1.5x desbalance):
  - Modelos entrenar√°n sin problemas
  - M√©trica accuracy es confiable
  
‚ö†Ô∏è DATASET DESBALANCEADO (> 1.5x):
  - Usar F1-Score en lugar de accuracy
  - Considerar class_weight='balanced' en modelos
  - T√©cnicas: SMOTE, oversampling, o ajustar threshold

‚úì HIGH CV STABILITY (std < 0.05):
  - Modelo ser√° consistente en producci√≥n
  - Confiable para despliegue
  
‚ö†Ô∏è HIGH VARIANCE (std >= 0.05):
  - Resultados pueden variar seg√∫n datos
  - M√°s datos de entrenamiento recomendado
  - Riesgo para despliegue en producci√≥n

‚úì HIGH F1-SCORE (> 0.80):
  - Modelo listo para producci√≥n
  - Depuraci√≥n limitada necesaria
  
‚ö†Ô∏è MODERATE F1 (0.65-0.80):
  - Aceptable para MVP
  - Monitore en producci√≥n
  
‚ùå LOW F1 (< 0.65):
  - Mejorar modelo antes de despliegue
  - Expandir dataset
  - Ajustar hiperpar√°metros
"""
    )
